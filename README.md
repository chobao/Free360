# Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views

### [Project Page](https://zju3dv.github.io/free360/) | [Video](https://youtu.be/hiSUzwdVHOY?si=qejS9NT74BZffQVd) | [Paper](https://drive.google.com/file/d/1UkJXCSd2XKcUf1MBEVoaW3NZphzQKbzv/view?usp=sharing)
<div align=center>
<img src="assets/teaser.gif" width="100%"/>
</div>

> [Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views](https://zju3dv.github.io/free360/)  
> 
> [Chong Bao](https://chobao.github.io/), [Xiyu Zhang](https://github.com/xyzhang77), [Zehao Yu](https://niujinshuchong.github.io/), [Jiale Shi](https://scholar.google.com/citations?user=vvW-UNMAAAAJ&hl=en), [Guofeng Zhang](http://www.cad.zju.edu.cn/home/gfzhang/), [Songyou Peng](https://pengsongyou.github.io/), [Zhaopeng Cui](https://zhpcui.github.io/). 
> 
> CVPR 2025
> 

## To-do

- [ ] Release training code.
- [ ] Release checkpoints.

## Dataset

We use [Mip-NeRF 360](https://jonbarron.info/mipnerf360/) and [Tanks and Temples](https://www.tanksandtemples.org/download/) as benchmark datasets. Their sparse-view splits used in paper can be downloaded [here](https://www.dropbox.com/scl/fo/1fajrtwox05ys49cmzb2f/AMBveN78Q_PYvlZaN_gMCn0?rlkey=i4aos0cal8ctyk46bwd2ztv5e&st=4canogy8&dl=0).

## Citing
```
@inproceedings{bao2025free,
    title={Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views},
    author={Bao, Chong and Zhang, Xiyu and Yu, Zehao and Shi, Jiale and Zhang, Guofeng and Peng, Songyou and Cui, Zhaopeng
    },
    booktitle={The IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR)},
    year={2025}
}
```